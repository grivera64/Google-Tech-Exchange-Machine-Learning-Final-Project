{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FWM79lj2LYI6"
      },
      "source": [
        "# Twitter Disasters Final Report | April 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authors\n",
        "\n",
        "- [Giovanni Rivera](https://github.com/grivera64); Intro to Machine Learning, Section A\n",
        "- [Oscar Jesus Zambrano](https://github.com/osc-zam22); Intro to Machine Learning, Section B"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WPFnCCd7O6fN"
      },
      "source": [
        "#### Setup Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwopORsO-yC",
        "outputId": "fa56efa0-7ab1-4f76-9319-137ec3d158f8"
      },
      "outputs": [],
      "source": [
        "# Ensure that we have the newest version of pip installed\n",
        "%pip install -q --upgrade pip\n",
        "\n",
        "# Install necessary libraries\n",
        "%pip install -q numpy\n",
        "%pip install -q pandas\n",
        "%pip install -q matplotlib\n",
        "%pip install -q seaborn\n",
        "\n",
        "# Helps avoid showing plots in a separate line\n",
        "# %matplotlib inline\n",
        "\n",
        "%pip install -q scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycGSQ31nQRa8"
      },
      "outputs": [],
      "source": [
        "# Import the modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "\n",
        "# Set the styling of the plt plots to darkgrid\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Removes error messsages and sets precision to 3 decimal places\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Our Story:\n",
        "TODO"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Our Task:\n",
        "\n",
        "We are designing a Machine Learning model using Tensorflow/Keras to identify whether a given tweet is a natural distaster.\n",
        "\n",
        "Throughout the notebook, we will refer to tweets about a natural distaster as part of the `postive class`, while tweets that aren't about a natural disaster as part of the `negative class`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UJCd5JzUNNuk"
      },
      "source": [
        "#### 1.1 Load the Data in a Colab Notebook\n",
        "\n",
        "We use a dataset from the Kaggle competition [Tech Exchange 2023 ML Project](https://www.kaggle.com/competitions/techexchange-2023-ml-project).\n",
        "\n",
        "You may find the dataset by navigating to the 'Data' tab in the link aforementioned. Under 'Data Explorer', you can download the following files:\n",
        "\n",
        "- `train.csv`: Contains the training data; we will use this dataset for our training and validation data.\n",
        "- `test.csv`: Contains our testing data; we will use this dataset for making our submissions to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct512u3DuP7E"
      },
      "outputs": [],
      "source": [
        "# Please update the Path here to the location of your train.csv and test.csv files\n",
        "path_to_csv = 'Data/techexchange-2023-ml-project'\n",
        "\n",
        "# Load the Data Frames from the Training and Testing Data Frame\n",
        "train_df = pd.read_csv(f'{path_to_csv}/train.csv')\n",
        "test_df = pd.read_csv(f'{path_to_csv}/test.csv')\n",
        "display(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate Data Frame for input and outputs\n",
        "\n",
        "input_names = ['id', 'keyword', 'location', 'text']\n",
        "input_df = train_df[input_names]\n",
        "display(input_df.head())\n",
        "\n",
        "output_names = ['target']\n",
        "output_df = train_df[output_names]\n",
        "display(output_df.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Convert our data into numpy arrays for usage in our ML models.\n",
        "\n",
        "Numpy will help us take full advantage of our GPU power to quickly perform training operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert into numpy data\n",
        "X_data = input_df.to_numpy()\n",
        "Y_data = output_df.to_numpy().flatten()\n",
        "\n",
        "print(X_data[:5])\n",
        "print(Y_data[:5])\n",
        "\n",
        "print(X_data.shape)\n",
        "print(Y_data.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Split the training data into 90% training and 10% for validation.\n",
        "\n",
        "We use Sklearn's train_test_split to split our `train.csv` dataset to create a 90:10 testing/validation split to use further down this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into train and test\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X_data, Y_data, train_size=0.90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Going through a few examples in the training split\n",
        "\n",
        "for index in range(2):\n",
        "    print('Text')\n",
        "    print(X_train[index])\n",
        "    print()\n",
        "    \n",
        "    print('Is Natural Disaster?')\n",
        "    print(Y_train[index], 'Yes' if Y_train[index] == 1 else 'No')\n",
        "    print('======================')\n",
        "    print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Create a Simple Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Returns a positive result, regardless of the input\n",
        "def baseline_model(text_inputs):\n",
        "    return 1\n",
        "\n",
        "# Vectorized version of the method to apply to numpy arrays properly\n",
        "baseline_model_np = np.vectorize(baseline_model, signature='(n) -> ()')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing the baseline on the \n",
        "baseline_predictions_train = baseline_model_np(X_train)\n",
        "\n",
        "for i in range(5):\n",
        "    print('Input:')\n",
        "    print(X_train[i])\n",
        "    print()\n",
        "\n",
        "    print('Output')\n",
        "    print(Y_train[i])\n",
        "    print()\n",
        "\n",
        "    print('Prediction')\n",
        "    print(baseline_predictions_train[i])\n",
        "    print('==================')\n",
        "    print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Calculate the Log Loss of our baseline model\n",
        "\n",
        "Since our baseline is simple, we can use this loss value to determine whether our models are more accurate than a naive approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculates Log Loss\n",
        "def calculate_loss(labels, predictions):\n",
        "    epsilon = 0.000001  # Prevents taking the natural log of non-positive values\n",
        "    ce_values = -labels * np.log(predictions + epsilon) - (1 - labels) * np.log(1 - predictions + epsilon)\n",
        "    loss = ce_values.mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the loss on the training portion of our train data\n",
        "training_loss = calculate_loss(Y_train, baseline_predictions_train)\n",
        "print('Training Loss:', training_loss)\n",
        "\n",
        "# Calculate the loss on the validation portion our our train data\n",
        "baseline_predictions_validation = baseline_model_np(X_validation)\n",
        "testing_loss = calculate_loss(Y_validation, baseline_predictions_validation)\n",
        "print('Validation Loss:', testing_loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Upload the baseline model to Kaggle\n",
        "\n",
        "We can then upload a `submission.csv` file to Kaggle to find the F1 score of our baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the submission CSV file for our Kaggle submission\n",
        "def save_to_submissions_csv(text_inputs, prediction_labels):\n",
        "    print('Generating \"submission.csv\" file...')\n",
        "\n",
        "    # Extract the ids of the text inputs and flatten to a 1D ndarray\n",
        "    test_ids = text_inputs[:,0].flatten()\n",
        "\n",
        "    # Write the submission file and save to 'submission.csv'\n",
        "    np.savetxt(\n",
        "        'submission.csv',\n",
        "        np.rec.fromarrays([test_ids, prediction_labels]),\n",
        "        fmt=['%s', '%d'],\n",
        "        delimiter=',',\n",
        "        header='id,target',\n",
        "        comments=''\n",
        "    )\n",
        "\n",
        "    # Show success!\n",
        "    print('Successfully created \"submission.csv\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reformat the single training dataframe to an input dataframe\n",
        "input_names = ['id', 'keyword', 'location', 'text']\n",
        "test_input_df = test_df[input_names]\n",
        "\n",
        "# Reformat the input dataframe into a numpy array for running through our model\n",
        "test_input_np = test_input_df.to_numpy()\n",
        "\n",
        "# Predict by using the baseline model on the test input and save to a .csv\n",
        "baseline_predictions_test = baseline_model_np(test_input_np)\n",
        "save_to_submissions_csv(test_input_np, baseline_predictions_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at the first few predictions to ensure things went smoothly\n",
        "pd.read_csv('submission.csv').head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Explore the frequency of common words\n",
        "\n",
        "Tweets can have all sorts of words inside of them, but we can always find common words that we can use for our vocabulary\n",
        "\n",
        "The motivation for this graph to see what type of words are commonly used within our tweets dataset to see what we should and should not include in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Plots the frequency of the top commonly used words in the provided tweets in\n",
        "# the positive and negative class\n",
        "def plot_frequency(tweets_np, labels_np, max_word_num=20):\n",
        "    # Creates a counter that keeps track of the frequency of words (similar to defaultdict)\n",
        "    pos_counter = Counter()\n",
        "    neg_counter = Counter()\n",
        "    tweets_np = np.copy(tweets_np) # Deep Copy of input\n",
        "\n",
        "    # Go through the tweets dataset\n",
        "    total_words = set()\n",
        "    for entry_index in range(tweets_np.shape[0]):\n",
        "        # Flatten all of the features into a single string\n",
        "        words = ' '.join([str(feature).lower() for feature in tweets_np[entry_index]])\n",
        "        # Count the frequency of each word\n",
        "        for word in words.split():\n",
        "            # Group all links as 1 token\n",
        "            if word.startswith('http'):\n",
        "                word = '<LINK>'\n",
        "            # Group all articles as 1 token\n",
        "            elif word in ['the', 'a', 'an']:\n",
        "                word = '<ARTICLE>'\n",
        "            \n",
        "            if labels_np[entry_index]:\n",
        "                pos_counter[word] += 1  # Positive entry\n",
        "            else:\n",
        "                neg_counter[word] += 1  # Negative entry\n",
        "\n",
        "            # For Debug purposes, saving all of the words we encounter\n",
        "            total_words.add(word)\n",
        "    \n",
        "    # Extract at most max_word_num words that are the most common words\n",
        "    # for both classes (and removes overlap)\n",
        "    top_pos_words = [word for word, _ in pos_counter.most_common(max_word_num // 2)]\n",
        "    top_neg_words = [word for word, _ in neg_counter.most_common(max_word_num // 2)]\n",
        "    top_words = set(top_pos_words + top_neg_words)\n",
        "\n",
        "    # Create a Data Frame for the collected data\n",
        "    result = {\n",
        "        'word': [word for word in top_words],\n",
        "        'pos count': [pos_counter[word] for word in top_words],\n",
        "        'neg count': [neg_counter[word] for word in top_words]\n",
        "    }\n",
        "    word_count_df = pd.DataFrame(data=result, columns=['word', 'pos count', 'neg count'])\n",
        "    word_count_df = word_count_df.set_index('word')\n",
        "    display(word_count_df)\n",
        "    \n",
        "    # Plot a bar graph that groups pos and neg count for a few of the most used words\n",
        "    pd.concat([word_count_df[['pos count']], word_count_df[['neg count']]], axis=1).plot.bar()\n",
        "\n",
        "    print(f'DEBUG: Total Words Len: {len(total_words)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display and plot at most 40 words from the X_data set\n",
        "plot_frequency(X_data, Y_data, max_word_num=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def length_plot(tweets_np , labels_np, interval_list):\n",
        "\n",
        "    # initializes maps to count based on intervals of words\n",
        "    pos_intervals = defaultdict(int)\n",
        "    neg_intervals = defaultdict(int)\n",
        "\n",
        "    # Convert the interval list into ranges for use below\n",
        "    interval_map = {}\n",
        "    for interval in interval_list:\n",
        "        # Parses interval strings into useable ranges\n",
        "        if '-' in interval:\n",
        "            start, end = map(lambda x: int(x), interval.split('-'))\n",
        "        else:\n",
        "            start, end = interval.split('+')[0], 285\n",
        "\n",
        "        interval_map[interval] = range(int(start), int(end) + 1)\n",
        "\n",
        "    # Track the counts of positive and negative inputs for each range from above\n",
        "    for entry_index in range(tweets_np.shape[0]):\n",
        "        # Flatten all of the features into a single string\n",
        "        words = ' '.join([str(feature) for feature in tweets_np[entry_index]]).split()\n",
        "\n",
        "        for interval in interval_list:\n",
        "            # Ignore words counts outside of our intervals\n",
        "            if len(words) not in interval_map[interval]:\n",
        "                continue\n",
        "\n",
        "            # Updates the counts of positive and negative entries in the dictionary\n",
        "            # based on the interval they are in\n",
        "            if labels_np[entry_index]:\n",
        "                pos_intervals[interval] += 1\n",
        "            else:\n",
        "                neg_intervals[interval] += 1\n",
        "\n",
        "    # Create a Data Frame for the collected data\n",
        "    result= {\n",
        "        'interval' : [ interval for interval in interval_list],\n",
        "        'pos intervals' : [pos_intervals[interval] for interval in interval_list],\n",
        "        'neg intervals' : [neg_intervals[interval] for interval in interval_list]\n",
        "    }\n",
        "    word_count_df = pd.DataFrame(data = result , columns=['interval', 'pos intervals', 'neg intervals'])\n",
        "    word_count_df = word_count_df.set_index('interval')\n",
        "\n",
        "    # Plot and Display the collected data\n",
        "    pd.concat([word_count_df[['pos intervals']], word_count_df[['neg intervals']]], axis=1).plot.bar()\n",
        "    display(word_count_df)\n",
        "\n",
        "    # Debugging code\n",
        "    print(neg_intervals)\n",
        "    print(pos_intervals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plots the count of positive and negative classes of X_data based on the given intervals\n",
        "intervals = ['0-10', '11-20' , '21-30' , '31-40' , '41-50' , '51-60' , '61-70', '71+']\n",
        "length_plot(X_data, Y_data, intervals)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Our Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def no_punc_no_link_(t):\n",
        "    remove_link_regex = r'(https?:\\/\\/)([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)'\n",
        "    remove_regex = r'[^\\w\\s <>]'\n",
        "    space_regex = '...'\n",
        "    result = tf.strings.lower(t)\n",
        "    result = tf.strings.regex_replace(result, remove_link_regex , '<LINK>')\n",
        "    result = tf.strings.regex_replace(result, remove_regex, ' ')\n",
        "    result = tf.strings.regex_replace(result , r'\\s{2,}' , ' ')\n",
        "    tf.print(result)\n",
        "\n",
        "no_punc_no_link_('I.am.cool  http://www.example.com')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Loss Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c4c6ce542ed86c85d22b49296a52397aea49807c5462a5cc5776ff93f0a8a801"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
